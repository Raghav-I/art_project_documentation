{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0TjfNjj1QWl"
      },
      "source": [
        "# **Mozart**: The ML Models Gradio Demo:\n",
        "\n",
        "Using Gradio 3.0, this demo is designed to showcase the backend of the Platform.\n",
        "\n",
        "-Bharath Raj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW6tl6Wm6q3U"
      },
      "source": [
        "##Installing Dependencies:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1kb_k5CEW5N"
      },
      "source": [
        "Dependencies for Colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "th85lTcr6_Gr",
        "outputId": "50a3f2e4-fa06-46c1-d5ad-102adc67727e"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "document.querySelector(\"#output-area\").appendChild(document.createTextNode(\"setup complete\"));\n",
              "\n",
              "for (rule of document.styleSheets[0].cssRules){\n",
              "  if (rule.selectorText=='body') break\n",
              "}\n",
              "rule.style.fontSize = '30px'\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import output\n",
        "\n",
        "nvidia_output = !nvidia-smi --query-gpu=memory.total --format=noheader,nounits,csv\n",
        "gpu_memory = int(nvidia_output[0])\n",
        "if gpu_memory < 14000:\n",
        "  output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n",
        "  warning_string = f\"--> GPU check: ONLY {gpu_memory} MiB available: Please use low quality or low res <--\"\n",
        "  print(warning_string)\n",
        "  output.eval_js('alert(\"Warning - low GPU (see message)\")')\n",
        "else:\n",
        "  print(f\"GPU check: {gpu_memory} MiB available: this should be fine\")\n",
        "\n",
        "from IPython.utils import io\n",
        "with io.capture_output() as captured:\n",
        "  !pip install torch==1.9.0+cu102 torchtext==0.10.0 torchvision==0.10.0+cu102 torch-optimizer==0.1.0 -f https://download.pytorch.org/whl/torch/ -f https://download.pytorch.org/whl/torchvision/\n",
        "  !git clone https://github.com/openai/CLIP\n",
        "  !git clone https://github.com/CompVis/taming-transformers.git\n",
        "  !rm -Rf clipit\n",
        "  !git clone https://github.com/bharathraj-v/clipit\n",
        "  !pip install ftfy regex tqdm omegaconf pytorch-lightning\n",
        "  !pip install kornia==0.6.1\n",
        "  !pip install imageio-ffmpeg   \n",
        "  !pip install einops\n",
        "  !pip install torch-optimizer\n",
        "  !pip install easydict\n",
        "  !pip install braceexpand\n",
        "  !pip install git+https://github.com/pvigier/perlin-numpy\n",
        "\n",
        "  !pip install svgwrite\n",
        "  !pip install svgpathtools\n",
        "  !pip install cssutils\n",
        "  !pip install numba\n",
        "  !pip install torch-tools\n",
        "  !pip install visdom\n",
        "\n",
        "\n",
        "  !git clone https://github.com/BachiLi/diffvg\n",
        "  %cd diffvg\n",
        "  !git submodule update --init --recursive\n",
        "  !python setup.py install\n",
        "  %cd ..\n",
        "  \n",
        "  !mkdir -p steps\n",
        "  !mkdir -p models\n",
        "\n",
        "output.clear()\n",
        "import sys\n",
        "sys.path.append(\"clipit\")\n",
        "\n",
        "result_msg = \"setup complete\"\n",
        "import IPython\n",
        "import os\n",
        "if not os.path.isfile(\"first_init_complete\"):\n",
        "  !mkdir -p models\n",
        "  os.mknod(\"first_init_complete\")\n",
        "  result_msg = \"Please choose Runtime -> Restart Runtime from the menu, and then run Setup again\"\n",
        "\n",
        "js_code = f'''\n",
        "document.querySelector(\"#output-area\").appendChild(document.createTextNode(\"{result_msg}\"));\n",
        "'''\n",
        "js_code += '''\n",
        "for (rule of document.styleSheets[0].cssRules){\n",
        "  if (rule.selectorText=='body') break\n",
        "}\n",
        "rule.style.fontSize = '30px'\n",
        "'''\n",
        "display(IPython.display.Javascript(js_code))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Ne7DIPGK5T"
      },
      "source": [
        "Dependencies for running locally:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "7TTYqEV8GKhN",
        "outputId": "b399e87b-ede6-4b79-b760-f7737b7b3bed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--> GPU check: ONLY 12031 MiB available: Please use low quality or low res <--\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "document.querySelector(\"#output-area\").appendChild(document.createTextNode(\"setup complete\"));\n",
              "\n",
              "for (rule of document.styleSheets[0].cssRules){\n",
              "  if (rule.selectorText=='body') break\n",
              "}\n",
              "rule.style.fontSize = '30px'\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#setting up working directory\n",
        "%cd bharathraj-v/\n",
        "%cd Documents/\n",
        "%cd Mozart/\n",
        "!pwd\n",
        "\n",
        "nvidia_output = !nvidia-smi --query-gpu=memory.total --format=noheader,nounits,csv\n",
        "gpu_memory = int(nvidia_output[0])\n",
        "if gpu_memory < 14000:\n",
        "  warning_string = f\"--> GPU check: ONLY {gpu_memory} MiB available: Please use low quality or low res <--\"\n",
        "  print(warning_string)\n",
        "else:\n",
        "  print(f\"GPU check: {gpu_memory} MiB available: this should be fine\")\n",
        "\n",
        "from IPython.utils import io\n",
        "with io.capture_output() as captured:\n",
        "  !pip install torch==1.9.0+cu102 torchtext==0.10.0 torchvision==0.10.0+cu102 torch-optimizer==0.1.0 -f https://download.pytorch.org/whl/torch/ -f https://download.pytorch.org/whl/torchvision/\n",
        "  !git clone https://github.com/openai/CLIP\n",
        "  !git clone https://github.com/CompVis/taming-transformers.git\n",
        "  !rm -Rf clipit\n",
        "  !git clone https://github.com/bharathraj-v/clipit\n",
        "  !pip install ftfy regex tqdm omegaconf pytorch-lightning\n",
        "  !pip install kornia==0.6.1\n",
        "  !pip install imageio-ffmpeg  \n",
        "  !pip install einops\n",
        "  !pip install torch-optimizer\n",
        "  !pip install easydict\n",
        "  !pip install braceexpand\n",
        "  !pip install git+https://github.com/pvigier/perlin-numpy\n",
        "\n",
        "  !pip install svgwrite\n",
        "  !pip install svgpathtools\n",
        "  !pip install cssutils\n",
        "  !pip install numba\n",
        "  !pip install torch-tools\n",
        "  !pip install visdom\n",
        "\n",
        "\n",
        "  !git clone https://github.com/BachiLi/diffvg\n",
        "  %cd diffvg\n",
        "  !git submodule update --init --recursive\n",
        "  !python setup.py install\n",
        "  %cd ..\n",
        "  \n",
        "  !mkdir -p steps\n",
        "  !mkdir -p models\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"clipit\")\n",
        "\n",
        "result_msg = \"setup complete\"\n",
        "import IPython\n",
        "import os\n",
        "if not os.path.isfile(\"first_init_complete\"):\n",
        "  !mkdir -p models\n",
        "  os.mknod(\"first_init_complete\")\n",
        "  result_msg = \"Please choose Runtime -> Restart Runtime from the menu, and then run Setup again\"\n",
        "\n",
        "js_code = f'''\n",
        "document.querySelector(\"#output-area\").appendChild(document.createTextNode(\"{result_msg}\"));\n",
        "'''\n",
        "js_code += '''\n",
        "for (rule of document.styleSheets[0].cssRules){\n",
        "  if (rule.selectorText=='body') break\n",
        "}\n",
        "rule.style.fontSize = '30px'\n",
        "'''\n",
        "display(IPython.display.Javascript(js_code))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfz-IzAGzIXV"
      },
      "source": [
        "## Importing Modules for Style Transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6UVxKnFF_f4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import time\n",
        "import functools\n",
        "import tensorflow_hub as hub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNf8R_zLdlLu"
      },
      "source": [
        "##Importing Modules for Super Resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mQKZuYRdp4E"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "from PIL import Image\n",
        "import requests\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EspTb6hOzVbC"
      },
      "source": [
        "##Importing Modules for VQGAN + Clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTU2YwPsMVCK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import clipit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L76i_XmIhnJX"
      },
      "source": [
        "##Function Definitions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egEC1CkbiabA"
      },
      "source": [
        "#####Style Transfer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWuieHsEieQK"
      },
      "outputs": [],
      "source": [
        "hub_model = hub.load(\"https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2\")\n",
        "def style_transfer(content_image, style_image):\n",
        "    content_image = tf.convert_to_tensor(content_image, np.float32)[tf.newaxis, ...] / 255.\n",
        "    style_image = tf.convert_to_tensor(style_image, np.float32)[tf.newaxis, ...] / 255.\n",
        "    output = hub_model(content_image, style_image)\n",
        "    stylized_image = output[0]\n",
        "    return Image.fromarray(np.uint8(stylized_image[0] * 255))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfgsKLX4hviQ"
      },
      "source": [
        "#####VQGAN + Clip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPupFTIeV1Ia"
      },
      "outputs": [],
      "source": [
        "def generate(prompt, generation_quality, detail):\n",
        "    torch.cuda.empty_cache()\n",
        "    clipit.reset_settings()\n",
        "    clipit.add_settings(prompts=prompt,\n",
        "                        aspect='square',\n",
        "                        quality=generation_quality,\n",
        "                        use_pixeldraw=False,\n",
        "                        use_clipdraw=False,\n",
        "                        make_video=False,\n",
        "                        iterations={'draft':30, 'normal': 60, 'better': 100}[detail])\n",
        "    settings = clipit.apply_settings()\n",
        "    clipit.do_init(settings)\n",
        "    clipit.do_run(settings)\n",
        "\n",
        "    return 'output.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke481mvwpFAR"
      },
      "source": [
        "#####Super Resolution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHdiER4tpIh3"
      },
      "outputs": [],
      "source": [
        "def return_resolution(path):\n",
        "  img = Image.open(path)\n",
        "  w, h = img.size\n",
        "  return (str(w) + \"x\" + str(h))\n",
        "\n",
        "def enhance(path):\n",
        "  Image.fromarray(path.astype('uint8'), 'RGB').save('temp.jpg', 'jpeg')\n",
        "  before = return_resolution(\"temp.jpg\")\n",
        "  r = requests.post(\n",
        "    \"https://api.deepai.org/api/torch-srgan\",\n",
        "    files={\n",
        "        'image': open('temp.jpg', 'rb')\n",
        "    },\n",
        "    headers={'api-key': 'quickstart-QUdJIGlzIGNvbWluZy4uLi4K'}\n",
        "  )\n",
        "  urllib.request.urlretrieve(r.json()[\"output_url\"],\"temp.jpg\")\n",
        "  img = Image.open(\"temp.jpg\")\n",
        "  after = return_resolution(\"temp.jpg\")\n",
        "  return img, \"Previous Resolution: \"+before+\"\\tSuper Resolution: \"+after\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ThIt0T70Gn3"
      },
      "source": [
        "#Gradio Interface:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrajuBEwhe4P"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXjaYWvm1dTz"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdBhp5K0mDUC"
      },
      "outputs": [],
      "source": [
        "def imgur_retreive(key):\n",
        "  urllib.request.urlretrieve(\"https://i.imgur.com/\"+key+\".png\",key+\".jpg\")\n",
        "  return key+\".jpg\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCOVE0lQ1Dn_"
      },
      "source": [
        "##Style Transfer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuQWU5aI1Jie"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "st_description = \"\"\"\n",
        "<center>\n",
        "<img src=https://i.imgur.com/goqyoWH.png width=700px>\n",
        "</center>\n",
        "\"\"\"\n",
        "\n",
        "starry_night = [imgur_retreive(\"dqpGGLm\"),imgur_retreive(\"MHTDaZ3\")]\n",
        "content = gr.inputs.Image(label=\"Content Image\")\n",
        "style = gr.inputs.Image(shape=(256, 256), label=\"Style Image\")\n",
        "\n",
        "\n",
        "editor = gr.Interface(style_transfer, \n",
        "                      inputs=[content, style], \n",
        "                      description = st_description,\n",
        "                      examples = [starry_night],\n",
        "                      article = \"Style transfer is a computer vision technique\"\n",
        "                      +\" that allows us to recompose the content of an image in the style of another\",\n",
        "                      outputs=\"image\",\n",
        "                      allow_flagging = \"never\",\n",
        "                      live=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaTjpSNR0xRl"
      },
      "source": [
        "## VQGAN + CLIP:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nckgMOwy07tn"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "ga_description = \"\"\"\n",
        "<center>\n",
        "<img src=https://i.imgur.com/lolHhBs.png width=700px>\n",
        "</center>\n",
        "\"\"\"\n",
        "prompt = gr.inputs.Textbox(default=\"Flying Cars\", label=\"Text Prompt\")\n",
        "generation_quality = gr.inputs.Radio(choices=['draft', 'normal', 'better'], label=\"Resolution\")\n",
        "detail = gr.inputs.Radio(choices=['draft', 'normal', 'better'], label=\"Detail\")\n",
        "\n",
        "\n",
        "\n",
        "generator = gr.Interface(generate, \n",
        "                         inputs=[prompt, generation_quality, detail], \n",
        "                         outputs=['image'], \n",
        "                         description = ga_description,\n",
        "                         enable_queue=True,\n",
        "                         allow_flagging = \"never\",\n",
        "                         live=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwxq244prnMh"
      },
      "source": [
        "## Super Resolution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA7zvOfsrqDC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "sr_description = \"\"\"\n",
        "<center>\n",
        "<img src=https://i.imgur.com/RhjYIZh.png width=700px>\n",
        "</center>\n",
        "\"\"\"\n",
        "original = gr.Image(shape=None, image_mode=\"RGB\", invert_colors=False, source=\"upload\", tool=\"editor\", type=\"numpy\", label=\"content\")\n",
        "text_output = gr.Textbox(show_label=False)\n",
        "enhancer = gr.Interface(enhance, \n",
        "                      inputs=[original], \n",
        "                      description = sr_description,\n",
        "                      article = \"2x your image resolution\",\n",
        "                      outputs=[\"image\", text_output],\n",
        "                      allow_flagging = \"never\",\n",
        "                      live=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H0CIKUIlieF"
      },
      "source": [
        "##Gallery:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx0cMxhblnmC"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "imgur_keys = [ \"srWawat\", \"tFXbZfI\",  \"6q6k737\", \"6mEeFQz\", \"zei8pqq\"]\n",
        "list_of_images = [imgur_retreive(i) for i in imgur_keys]\n",
        "\n",
        "def infer():\n",
        "    return list_of_images\n",
        "\n",
        "gl_description = \"\"\"\n",
        "<center>\n",
        "<img src=https://i.imgur.com/ncvkiph.png width=700px>\n",
        "</center>\n",
        "\"\"\"\n",
        "gallery=gr.Gallery(label=\"Mozart Gallery\").style(grid=[5], height=\"auto\")\n",
        "gallery_interface = gr.Interface(infer, \n",
        "                                 inputs=None, \n",
        "                                 live=True, \n",
        "                                 allow_flagging=\"never\", \n",
        "                                 description = gl_description,\n",
        "                                 article = \"(Some of the art generated by Mozart\",\n",
        "                                 outputs=gallery)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fmSQpq__PLf"
      },
      "source": [
        "##Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N1zAVrua_UOo",
        "outputId": "293e9e6c-332d-4952-cfd9-7bfa2141d88b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://16428.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://16428.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/routes.py\", line 256, in run_predict\n",
            "    fn_index, raw_input, username, session_state\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/blocks.py\", line 546, in process_api\n",
            "    predictions, duration = await self.call_function(fn_index, processed_input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/blocks.py\", line 462, in call_function\n",
            "    block_fn.fn, *processed_input, limiter=self.limiter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/to_thread.py\", line 32, in run_sync\n",
            "    func, *args, cancellable=cancellable, limiter=limiter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 516, in <lambda>\n",
            "    else self.run_prediction(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 718, in run_prediction\n",
            "    prediction = predict_fn(*processed_input)\n",
            "  File \"<ipython-input-5-01f592387636>\", line 16, in enhance\n",
            "    urllib.request.urlretrieve(r.json()[\"output_url\"],\"temp.jpg\")\n",
            "KeyError: 'output_url'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/routes.py\", line 256, in run_predict\n",
            "    fn_index, raw_input, username, session_state\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/blocks.py\", line 546, in process_api\n",
            "    predictions, duration = await self.call_function(fn_index, processed_input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/blocks.py\", line 462, in call_function\n",
            "    block_fn.fn, *processed_input, limiter=self.limiter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/to_thread.py\", line 32, in run_sync\n",
            "    func, *args, cancellable=cancellable, limiter=limiter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 516, in <lambda>\n",
            "    else self.run_prediction(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 718, in run_prediction\n",
            "    prediction = predict_fn(*processed_input)\n",
            "  File \"<ipython-input-5-01f592387636>\", line 16, in enhance\n",
            "    urllib.request.urlretrieve(r.json()[\"output_url\"],\"temp.jpg\")\n",
            "KeyError: 'output_url'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/routes.py\", line 256, in run_predict\n",
            "    fn_index, raw_input, username, session_state\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/blocks.py\", line 546, in process_api\n",
            "    predictions, duration = await self.call_function(fn_index, processed_input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/blocks.py\", line 462, in call_function\n",
            "    block_fn.fn, *processed_input, limiter=self.limiter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/to_thread.py\", line 32, in run_sync\n",
            "    func, *args, cancellable=cancellable, limiter=limiter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 516, in <lambda>\n",
            "    else self.run_prediction(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 718, in run_prediction\n",
            "    prediction = predict_fn(*processed_input)\n",
            "  File \"<ipython-input-5-01f592387636>\", line 16, in enhance\n",
            "    urllib.request.urlretrieve(r.json()[\"output_url\"],\"temp.jpg\")\n",
            "KeyError: 'output_url'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f5ef2beced0>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://16428.gradio.app')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "app = gr.TabbedInterface([generator, editor, enhancer, gallery_interface], [\"Generate Art\", \"Style Transfer\", \"Super Resolution\", \"Mozart Gallery\"])\n",
        "\n",
        "app.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggMZTMf7Ky5E"
      },
      "source": [
        "Clean Cache:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dRNmoctK1zX"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ui test.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}