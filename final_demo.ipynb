{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0TjfNjj1QWl"
      },
      "source": [
        "# **Mozart**: The ML Models Gradio Demo:\n",
        "\n",
        "Using Gradio 3.0, this demo is designed to showcase the backend of the Platform.\n",
        "\n",
        "-Bharath Raj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW6tl6Wm6q3U"
      },
      "source": [
        "##Installing Dependencies:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1kb_k5CEW5N"
      },
      "source": [
        "Dependencies for Colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "th85lTcr6_Gr"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "\n",
        "nvidia_output = !nvidia-smi --query-gpu=memory.total --format=noheader,nounits,csv\n",
        "gpu_memory = int(nvidia_output[0])\n",
        "if gpu_memory < 14000:\n",
        "  output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n",
        "  warning_string = f\"--> GPU check: ONLY {gpu_memory} MiB available: Please use low quality or low res <--\"\n",
        "  print(warning_string)\n",
        "  output.eval_js('alert(\"Warning - low GPU (see message)\")')\n",
        "else:\n",
        "  print(f\"GPU check: {gpu_memory} MiB available: this should be fine\")\n",
        "\n",
        "from IPython.utils import io\n",
        "with io.capture_output() as captured:\n",
        "  !pip install torch==1.9.0+cu102 torchtext==0.10.0 torchvision==0.10.0+cu102 torch-optimizer==0.1.0 -f https://download.pytorch.org/whl/torch/ -f https://download.pytorch.org/whl/torchvision/\n",
        "  !git clone https://github.com/openai/CLIP\n",
        "  !git clone https://github.com/CompVis/taming-transformers.git\n",
        "  !rm -Rf clipit\n",
        "  !git clone https://github.com/bharathraj-v/clipit\n",
        "  !pip install ftfy regex tqdm omegaconf pytorch-lightning\n",
        "  !pip install kornia==0.6.1\n",
        "  !pip install imageio-ffmpeg   \n",
        "  !pip install einops\n",
        "  !pip install torch-optimizer\n",
        "  !pip install easydict\n",
        "  !pip install braceexpand\n",
        "  !pip install git+https://github.com/pvigier/perlin-numpy\n",
        "\n",
        "  !pip install svgwrite\n",
        "  !pip install svgpathtools\n",
        "  !pip install cssutils\n",
        "  !pip install numba\n",
        "  !pip install torch-tools\n",
        "  !pip install visdom\n",
        "\n",
        "\n",
        "  !git clone https://github.com/BachiLi/diffvg\n",
        "  %cd diffvg\n",
        "  !git submodule update --init --recursive\n",
        "  !python setup.py install\n",
        "  %cd ..\n",
        "  \n",
        "  !mkdir -p steps\n",
        "  !mkdir -p models\n",
        "\n",
        "output.clear()\n",
        "import sys\n",
        "sys.path.append(\"clipit\")\n",
        "\n",
        "result_msg = \"setup complete\"\n",
        "import IPython\n",
        "import os\n",
        "if not os.path.isfile(\"first_init_complete\"):\n",
        "  !mkdir -p models\n",
        "  os.mknod(\"first_init_complete\")\n",
        "  result_msg = \"Please choose Runtime -> Restart Runtime from the menu, and then run Setup again\"\n",
        "\n",
        "js_code = f'''\n",
        "document.querySelector(\"#output-area\").appendChild(document.createTextNode(\"{result_msg}\"));\n",
        "'''\n",
        "js_code += '''\n",
        "for (rule of document.styleSheets[0].cssRules){\n",
        "  if (rule.selectorText=='body') break\n",
        "}\n",
        "rule.style.fontSize = '30px'\n",
        "'''\n",
        "display(IPython.display.Javascript(js_code))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Ne7DIPGK5T"
      },
      "source": [
        "Dependencies for running locally:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TTYqEV8GKhN"
      },
      "outputs": [],
      "source": [
        "#setting up working directory\n",
        "%cd bharathraj-v/\n",
        "%cd Documents/\n",
        "%cd Mozart/\n",
        "!pwd\n",
        "\n",
        "nvidia_output = !nvidia-smi --query-gpu=memory.total --format=noheader,nounits,csv\n",
        "gpu_memory = int(nvidia_output[0])\n",
        "if gpu_memory < 14000:\n",
        "  warning_string = f\"--> GPU check: ONLY {gpu_memory} MiB available: Please use low quality or low res <--\"\n",
        "  print(warning_string)\n",
        "else:\n",
        "  print(f\"GPU check: {gpu_memory} MiB available: this should be fine\")\n",
        "\n",
        "from IPython.utils import io\n",
        "with io.capture_output() as captured:\n",
        "  !pip install torch==1.9.0+cu102 torchtext==0.10.0 torchvision==0.10.0+cu102 torch-optimizer==0.1.0 -f https://download.pytorch.org/whl/torch/ -f https://download.pytorch.org/whl/torchvision/\n",
        "  !git clone https://github.com/openai/CLIP\n",
        "  !git clone https://github.com/CompVis/taming-transformers.git\n",
        "  !rm -Rf clipit\n",
        "  !git clone https://github.com/bharathraj-v/clipit\n",
        "  !pip install ftfy regex tqdm omegaconf pytorch-lightning\n",
        "  !pip install kornia==0.6.1\n",
        "  !pip install imageio-ffmpeg  \n",
        "  !pip install einops\n",
        "  !pip install torch-optimizer\n",
        "  !pip install easydict\n",
        "  !pip install braceexpand\n",
        "  !pip install git+https://github.com/pvigier/perlin-numpy\n",
        "\n",
        "  !pip install svgwrite\n",
        "  !pip install svgpathtools\n",
        "  !pip install cssutils\n",
        "  !pip install numba\n",
        "  !pip install torch-tools\n",
        "  !pip install visdom\n",
        "\n",
        "\n",
        "  !git clone https://github.com/BachiLi/diffvg\n",
        "  %cd diffvg\n",
        "  !git submodule update --init --recursive\n",
        "  !python setup.py install\n",
        "  %cd ..\n",
        "  \n",
        "  !mkdir -p steps\n",
        "  !mkdir -p models\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"clipit\")\n",
        "\n",
        "result_msg = \"setup complete\"\n",
        "import IPython\n",
        "import os\n",
        "if not os.path.isfile(\"first_init_complete\"):\n",
        "  !mkdir -p models\n",
        "  os.mknod(\"first_init_complete\")\n",
        "  result_msg = \"Please choose Runtime -> Restart Runtime from the menu, and then run Setup again\"\n",
        "\n",
        "js_code = f'''\n",
        "document.querySelector(\"#output-area\").appendChild(document.createTextNode(\"{result_msg}\"));\n",
        "'''\n",
        "js_code += '''\n",
        "for (rule of document.styleSheets[0].cssRules){\n",
        "  if (rule.selectorText=='body') break\n",
        "}\n",
        "rule.style.fontSize = '30px'\n",
        "'''\n",
        "display(IPython.display.Javascript(js_code))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfz-IzAGzIXV"
      },
      "source": [
        "## Importing Modules for Style Transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6UVxKnFF_f4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import time\n",
        "import functools\n",
        "import tensorflow_hub as hub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNf8R_zLdlLu"
      },
      "source": [
        "##Importing Modules for Super Resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mQKZuYRdp4E"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "from PIL import Image\n",
        "import requests\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EspTb6hOzVbC"
      },
      "source": [
        "##Importing Modules for VQGAN + Clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTU2YwPsMVCK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import clipit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L76i_XmIhnJX"
      },
      "source": [
        "##Function Definitions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egEC1CkbiabA"
      },
      "source": [
        "#####Style Transfer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWuieHsEieQK"
      },
      "outputs": [],
      "source": [
        "hub_model = hub.load(\"https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2\")\n",
        "def style_transfer(content_image, style_image):\n",
        "    content_image = tf.convert_to_tensor(content_image, np.float32)[tf.newaxis, ...] / 255.\n",
        "    style_image = tf.convert_to_tensor(style_image, np.float32)[tf.newaxis, ...] / 255.\n",
        "    output = hub_model(content_image, style_image)\n",
        "    stylized_image = output[0]\n",
        "    return Image.fromarray(np.uint8(stylized_image[0] * 255))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfgsKLX4hviQ"
      },
      "source": [
        "#####VQGAN + Clip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPupFTIeV1Ia"
      },
      "outputs": [],
      "source": [
        "def generate(prompt, generation_quality, detail):\n",
        "    torch.cuda.empty_cache()\n",
        "    clipit.reset_settings()\n",
        "    clipit.add_settings(prompts=prompt,\n",
        "                        aspect='square',\n",
        "                        quality=generation_quality,\n",
        "                        use_pixeldraw=False,\n",
        "                        use_clipdraw=False,\n",
        "                        make_video=False,\n",
        "                        iterations={'draft':30, 'normal': 60, 'better': 100}[detail])\n",
        "    settings = clipit.apply_settings()\n",
        "    clipit.do_init(settings)\n",
        "    clipit.do_run(settings)\n",
        "\n",
        "    return 'output.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke481mvwpFAR"
      },
      "source": [
        "#####Super Resolution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHdiER4tpIh3"
      },
      "outputs": [],
      "source": [
        "def enhance(path):\n",
        "  Image.fromarray(path.astype('uint8'), 'RGB').save('temp.jpg', 'jpeg')\n",
        "  \n",
        "  r = requests.post(\n",
        "    \"https://api.deepai.org/api/waifu2x\",\n",
        "    files={\n",
        "        'image': open('temp.jpg', 'rb')\n",
        "    },\n",
        "    headers={'api-key': 'quickstart-QUdJIGlzIGNvbWluZy4uLi4K'}\n",
        "  )\n",
        "  urllib.request.urlretrieve(r.json()[\"output_url\"],\"temp.jpg\")\n",
        "  img = Image.open(\"temp.jpg\")\n",
        "  return img\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ThIt0T70Gn3"
      },
      "source": [
        "#Gradio Interface:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrajuBEwhe4P"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXjaYWvm1dTz"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCOVE0lQ1Dn_"
      },
      "source": [
        "##Style Transfer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuQWU5aI1Jie"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "st_description = \"\"\"\n",
        "<center>\n",
        "<img src=https://i.imgur.com/goqyoWH.png width=700px>\n",
        "</center>\n",
        "\"\"\"\n",
        "\n",
        "urllib.request.urlretrieve(\"https://i.imgur.com/dqpGGLm.png\",\"stock.jpg\")\n",
        "urllib.request.urlretrieve(\"https://i.imgur.com/MHTDaZ3.png\",\"starrynight.jpg\")\n",
        "starry_night = [\"stock.jpg\",\"starrynight.jpg\"]\n",
        "content = gr.inputs.Image(label=\"Content Image\")\n",
        "style = gr.inputs.Image(shape=(256, 256), label=\"Style Image\")\n",
        "\n",
        "\n",
        "editor = gr.Interface(style_transfer, \n",
        "                      inputs=[content, style], \n",
        "                      description = st_description,\n",
        "                      examples = [starry_night],\n",
        "                      article = \"Style transfer is a computer vision technique\"\n",
        "                      +\" that allows us to recompose the content of an image in the style of another\",\n",
        "                      outputs=\"image\",\n",
        "\n",
        "                      allow_flagging = \"never\",\n",
        "                      live=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaTjpSNR0xRl"
      },
      "source": [
        "## VQGAN + CLIP:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nckgMOwy07tn"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "ga_description = \"\"\"\n",
        "<center>\n",
        "<img src=https://i.imgur.com/lolHhBs.png width=700px>\n",
        "</center>\n",
        "\"\"\"\n",
        "prompt = gr.inputs.Textbox(default=\"Flying Cars\", label=\"Text Prompt\")\n",
        "generation_quality = gr.inputs.Radio(choices=['draft', 'normal', 'better'], label=\"Resolution\")\n",
        "detail = gr.inputs.Radio(choices=['draft', 'normal', 'better'], label=\"Detail\")\n",
        "\n",
        "\n",
        "generator = gr.Interface(generate, \n",
        "                         inputs=[prompt, generation_quality, detail], \n",
        "                         outputs=['image'], \n",
        "                         description = ga_description,\n",
        "                         enable_queue=True, \n",
        "                         live=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwxq244prnMh"
      },
      "source": [
        "## Super Resolution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA7zvOfsrqDC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "sr_description = \"\"\"\n",
        "<center>\n",
        "<img src=https://i.imgur.com/RhjYIZh.png width=700px>\n",
        "</center>\n",
        "\"\"\"\n",
        "original = gr.Image(shape=None, image_mode=\"RGB\", invert_colors=False, source=\"upload\", tool=\"editor\", type=\"numpy\", label=\"content\")\n",
        "\n",
        "enhancer = gr.Interface(enhance, \n",
        "                      inputs=[original], \n",
        "                      description = sr_description,\n",
        "                      article = \"2x your image resolution\",\n",
        "                      outputs=[\"image\"],\n",
        "                      allow_flagging = \"never\",\n",
        "                      live=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fmSQpq__PLf"
      },
      "source": [
        "## Combined Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "N1zAVrua_UOo",
        "outputId": "f6cc14da-0875-4b99-d00b-9239b60e29ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://52131.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://52131.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "combined = gr.TabbedInterface([generator, editor, enhancer], [\"Generate Art\", \"Style Transfer\", \"Super Resolution\"])\n",
        "combined.launch(debug=True, share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggMZTMf7Ky5E"
      },
      "source": [
        "Clean Cache:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dRNmoctK1zX"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "final_demo.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}