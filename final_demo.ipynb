{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sW6tl6Wm6q3U",
        "TfgsKLX4hviQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Artszy**: The ML Models Gradio Demo:\n",
        "\n",
        "Using Gradio 3.0, this demo is designed to showcase the backend of the Artszy Platform. The Final Product would be a web app built using React, FastAPI and Python.\n",
        "\n",
        "This demo showcases everything but the UI of the platform.\n",
        "\n",
        "-Bharath Raj"
      ],
      "metadata": {
        "id": "U0TjfNjj1QWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Installing Dependencies:"
      ],
      "metadata": {
        "id": "sW6tl6Wm6q3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "\n",
        "nvidia_output = !nvidia-smi --query-gpu=memory.total --format=noheader,nounits,csv\n",
        "gpu_memory = int(nvidia_output[0])\n",
        "if gpu_memory < 14000:\n",
        "  output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n",
        "  warning_string = f\"--> GPU check: ONLY {gpu_memory} MiB available: Please use low quality or low res <--\"\n",
        "  print(warning_string)\n",
        "  output.eval_js('alert(\"Warning - low GPU (see message)\")')\n",
        "else:\n",
        "  print(f\"GPU check: {gpu_memory} MiB available: this should be fine\")\n",
        "\n",
        "from IPython.utils import io\n",
        "with io.capture_output() as captured:\n",
        "  !pip install torch==1.9.0+cu102 torchtext==0.10.0 torchvision==0.10.0+cu102 torch-optimizer==0.1.0 -f https://download.pytorch.org/whl/torch/ -f https://download.pytorch.org/whl/torchvision/\n",
        "  !git clone https://github.com/openai/CLIP\n",
        "  !git clone https://github.com/CompVis/taming-transformers.git\n",
        "  !rm -Rf clipit\n",
        "  !git clone https://github.com/mfrashad/clipit.git\n",
        "  !pip install ftfy regex tqdm omegaconf pytorch-lightning\n",
        "  !pip install kornia==0.6.1\n",
        "  !pip install imageio-ffmpeg   \n",
        "  !pip install einops\n",
        "  !pip install torch-optimizer\n",
        "  !pip install easydict\n",
        "  !pip install braceexpand\n",
        "  !pip install git+https://github.com/pvigier/perlin-numpy\n",
        "\n",
        "  !pip install svgwrite\n",
        "  !pip install svgpathtools\n",
        "  !pip install cssutils\n",
        "  !pip install numba\n",
        "  !pip install torch-tools\n",
        "  !pip install visdom\n",
        "\n",
        "  !pip install gradio\n",
        "  \n",
        "  !git clone https://github.com/BachiLi/diffvg\n",
        "  %cd diffvg\n",
        "  \n",
        "  !git submodule update --init --recursive\n",
        "  !python setup.py install\n",
        "  %cd ..\n",
        "  \n",
        "  !mkdir -p steps\n",
        "  !mkdir -p models\n",
        "\n",
        "output.clear()\n",
        "import sys\n",
        "sys.path.append(\"clipit\")\n",
        "\n",
        "result_msg = \"setup complete\"\n",
        "import IPython\n",
        "import os\n",
        "if not os.path.isfile(\"first_init_complete\"):\n",
        "  !mkdir -p models\n",
        "  os.mknod(\"first_init_complete\")\n",
        "  result_msg = \"Please choose Runtime -> Restart Runtime from the menu, and then run Setup again\"\n",
        "\n",
        "js_code = f'''\n",
        "document.querySelector(\"#output-area\").appendChild(document.createTextNode(\"{result_msg}\"));\n",
        "'''\n",
        "js_code += '''\n",
        "for (rule of document.styleSheets[0].cssRules){\n",
        "  if (rule.selectorText=='body') break\n",
        "}\n",
        "rule.style.fontSize = '30px'\n",
        "'''\n",
        "display(IPython.display.Javascript(js_code))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th85lTcr6_Gr",
        "outputId": "30eca42f-b69b-4549-a219-366ec974be04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU check: 15109 MiB available: this should be fine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Modules for Style Transfer and Super Resolution"
      ],
      "metadata": {
        "id": "Wfz-IzAGzIXV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B6UVxKnFF_f4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import time\n",
        "import functools\n",
        "import tensorflow_hub as hub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Modules for VQGAN + Clip"
      ],
      "metadata": {
        "id": "EspTb6hOzVbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import clipit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTU2YwPsMVCK",
        "outputId": "478fbf8f-5fdb-4609-bd57-9ef4f57b1648"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3883008/45929032 bytes (8.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7823360/45929032 bytes (17.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11812864/45929032 bytes (25.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15892480/45929032 bytes (34.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20004864/45929032 bytes (43.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24109056/45929032 bytes (52.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28172288/45929032 bytes (61.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32186368/45929032 bytes (70.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36102144/45929032 bytes (78.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39952384/45929032 bytes (87.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b43859968/45929032 bytes (95.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Function Definitions:"
      ],
      "metadata": {
        "id": "L76i_XmIhnJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Style Transfer:"
      ],
      "metadata": {
        "id": "egEC1CkbiabA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_image(tensor):\n",
        "  tensor = tensor*255\n",
        "  tensor = np.array(tensor, dtype=np.uint8)\n",
        "  if np.ndim(tensor)>3:\n",
        "    assert tensor.shape[0] == 1\n",
        "    tensor = tensor[0]\n",
        "  return PIL.Image.fromarray(tensor)\n",
        "\n",
        "\n",
        "def convert_img(img, quality):\n",
        "  max_dim = 256 * quality\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "  long_dim = max(shape)\n",
        "  scale = max_dim / long_dim\n",
        "  new_shape = tf.cast(shape * scale, tf.int32)\n",
        "  img = tf.image.resize(img, new_shape)\n",
        "  img = img[tf.newaxis, :]\n",
        "  return img\n",
        "\n",
        "def style_transfer(content, style, quality):\n",
        "    hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
        "    content = convert_img(content, quality)\n",
        "    style = convert_img(style, quality)\n",
        "    stylized_image = hub_model(tf.constant(content), tf.constant(style))[0]\n",
        "    return tensor_to_image(stylized_image)"
      ],
      "metadata": {
        "id": "DWuieHsEieQK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####VQGAN + Clip:"
      ],
      "metadata": {
        "id": "TfgsKLX4hviQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt, generation_quality, detail):\n",
        "    detail_dict = {'draft':30, 'normal': 80, 'better': 150}\n",
        "    torch.cuda.empty_cache()\n",
        "    clipit.reset_settings()\n",
        "    clipit.add_settings(prompts=prompt,\n",
        "                        aspect='square',\n",
        "                        quality=generation_quality,\n",
        "                        use_pixeldraw=False,\n",
        "                        use_clipdraw=False,\n",
        "                        make_video=False,\n",
        "                        iterations=detail_dict[detail])\n",
        "    settings = clipit.apply_settings()\n",
        "    clipit.do_init(settings)\n",
        "    clipit.do_run(settings)\n",
        "\n",
        "    return 'output.png'"
      ],
      "metadata": {
        "id": "rPupFTIeV1Ia"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradio Interface:\n",
        "\n"
      ],
      "metadata": {
        "id": "1ThIt0T70Gn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "DrajuBEwhe4P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "kXjaYWvm1dTz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Style Transfer:"
      ],
      "metadata": {
        "id": "FCOVE0lQ1Dn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "content = gr.inputs.Image(shape=None, image_mode=\"RGB\", invert_colors=False, source=\"upload\", tool=\"editor\", type=\"numpy\", label=\"content\")\n",
        "style = gr.inputs.Image(shape=None, image_mode=\"RGB\", invert_colors=False, source=\"upload\", tool=\"editor\", type=\"numpy\", label=\"Style\")\n",
        "quality = gr.inputs.Radio(choices=[1, 2, 3, 4], label=\"Quality\")\n",
        "\n",
        "editor = gr.Interface(style_transfer, \n",
        "                      inputs=[content, style, quality], \n",
        "                      title = \"Style Transfer\",\n",
        "                      article = \"Style transfer is a computer vision technique\"\n",
        "                      +\"that allows us to recompose the content of an image in the style of another\",\n",
        "                      outputs=[\"image\"],\n",
        "                      allow_flagging = \"never\",\n",
        "                      live=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuQWU5aI1Jie",
        "outputId": "84bef49f-fac8-4563-e3e4-46c56e0d8922"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/gradio/inputs.py:272: DeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  DeprecationWarning,\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/gradio/inputs.py:272: DeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  DeprecationWarning,\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.7/dist-packages/gradio/inputs.py:194: DeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  DeprecationWarning,\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VQGAN + CLIP:"
      ],
      "metadata": {
        "id": "JaTjpSNR0xRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "prompt = gr.inputs.Textbox(default=\"Flying Cars\", label=\"Text Prompt\")\n",
        "generation_quality = gr.inputs.Radio(choices=['draft', 'normal', 'better'], label=\"Resolution\")\n",
        "detail = gr.inputs.Radio(choices=['draft', 'normal', 'better'], label=\"Detail\")\n",
        "\n",
        "\n",
        "generator = gr.Interface(generate, \n",
        "                         inputs=[prompt, generation_quality, detail], \n",
        "                         outputs=['image'], \n",
        "                         title = \"Text to Art\",\n",
        "                         enable_queue=True, \n",
        "                         live=False)"
      ],
      "metadata": {
        "id": "nckgMOwy07tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combined Interface"
      ],
      "metadata": {
        "id": "6fmSQpq__PLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined = gr.TabbedInterface([generator, editor], [\"Generate Art\", \"Style Transfer\"])\n",
        "combined.launch(debug=True)"
      ],
      "metadata": {
        "id": "N1zAVrua_UOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean Cache:"
      ],
      "metadata": {
        "id": "ggMZTMf7Ky5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "6dRNmoctK1zX"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}