{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Artszy**: The ML Models Gradio Demo:\n",
        "\n",
        "Using Gradio 3.0, this demo is designed to showcase the backend of the Artszy Platform. The Final Product would be a web app built using React, FastAPI and Python.\n",
        "\n",
        "This demo showcases everything but the UI of the platform.\n",
        "\n",
        "-Bharath Raj"
      ],
      "metadata": {
        "id": "U0TjfNjj1QWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Installing Dependencies:"
      ],
      "metadata": {
        "id": "sW6tl6Wm6q3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nvidia_output = !nvidia-smi --query-gpu=memory.total --format=noheader,nounits,csv\n",
        "gpu_memory = int(nvidia_output[0])\n",
        "if gpu_memory < 14000:\n",
        "  warning_string = f\"--> GPU check: ONLY {gpu_memory} MiB available: Please use low quality or low res <--\"\n",
        "  print(warning_string)\n",
        "else:\n",
        "  print(f\"GPU check: {gpu_memory} MiB available: this should be fine\")\n",
        "\n",
        "from IPython.utils import io\n",
        "with io.capture_output() as captured:\n",
        "  !pip install torch==1.9.0+cu102 torchtext==0.10.0 torchvision==0.10.0+cu102 torch-optimizer==0.1.0 -f https://download.pytorch.org/whl/torch/ -f https://download.pytorch.org/whl/torchvision/\n",
        "  !git clone https://github.com/openai/CLIP\n",
        "  !git clone https://github.com/CompVis/taming-transformers.git\n",
        "  !rm -Rf clipit\n",
        "  !git clone https://github.com/mfrashad/clipit.git\n",
        "  !pip install ftfy regex tqdm omegaconf pytorch-lightning\n",
        "  !pip install kornia==0.6.1\n",
        "  !pip install imageio-ffmpeg   \n",
        "  !pip install einops\n",
        "  !pip install torch-optimizer\n",
        "  !pip install easydict\n",
        "  !pip install braceexpand\n",
        "  !pip install git+https://github.com/pvigier/perlin-numpy\n",
        "\n",
        "  !pip install svgwrite\n",
        "  !pip install svgpathtools\n",
        "  !pip install cssutils\n",
        "  !pip install numba\n",
        "  !pip install torch-tools\n",
        "  !pip install visdom\n",
        "  \n",
        "  !git clone https://github.com/BachiLi/diffvg\n",
        "  %cd diffvg\n",
        "  \n",
        "  !git submodule update --init --recursive\n",
        "  !python setup.py install\n",
        "  %cd ..\n",
        "  \n",
        "  !mkdir -p steps\n",
        "  !mkdir -p models\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"clipit\")\n",
        "\n",
        "result_msg = \"setup complete\"\n",
        "import IPython\n",
        "import os\n",
        "if not os.path.isfile(\"first_init_complete\"):\n",
        "  !mkdir -p models\n",
        "  os.mknod(\"first_init_complete\")\n",
        "  result_msg = \"Please choose Runtime -> Restart Runtime from the menu, and then run Setup again\"\n",
        "\n",
        "js_code = f'''\n",
        "document.querySelector(\"#output-area\").appendChild(document.createTextNode(\"{result_msg}\"));\n",
        "'''\n",
        "js_code += '''\n",
        "for (rule of document.styleSheets[0].cssRules){\n",
        "  if (rule.selectorText=='body') break\n",
        "}\n",
        "rule.style.fontSize = '30px'\n",
        "'''\n",
        "display(IPython.display.Javascript(js_code))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "th85lTcr6_Gr",
        "outputId": "3ec727dc-b6ea-4f57-fc9d-8342595b70d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> GPU check: ONLY 8192 MiB available: Please use low quality or low res <--\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "document.querySelector(\"#output-area\").appendChild(document.createTextNode(\"setup complete\"));\n",
              "\n",
              "for (rule of document.styleSheets[0].cssRules){\n",
              "  if (rule.selectorText=='body') break\n",
              "}\n",
              "rule.style.fontSize = '30px'\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Modules for Style Transfer"
      ],
      "metadata": {
        "id": "Wfz-IzAGzIXV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B6UVxKnFF_f4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import time\n",
        "import functools\n",
        "import tensorflow_hub as hub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Modules for Super Resolution"
      ],
      "metadata": {
        "id": "mNf8R_zLdlLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "from PIL import Image\n",
        "import requests\n",
        "import shutil"
      ],
      "metadata": {
        "id": "4mQKZuYRdp4E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Modules for VQGAN + Clip"
      ],
      "metadata": {
        "id": "EspTb6hOzVbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import clipit"
      ],
      "metadata": {
        "id": "DTU2YwPsMVCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Function Definitions:"
      ],
      "metadata": {
        "id": "L76i_XmIhnJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Style Transfer:"
      ],
      "metadata": {
        "id": "egEC1CkbiabA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_image(tensor):\n",
        "  tensor = tensor*255\n",
        "  tensor = np.array(tensor, dtype=np.uint8)\n",
        "  if np.ndim(tensor)>3:\n",
        "    assert tensor.shape[0] == 1\n",
        "    tensor = tensor[0]\n",
        "  return PIL.Image.fromarray(tensor)\n",
        "\n",
        "def convert_img(img, quality):\n",
        "  max_dim = 256 * quality\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "  long_dim = max(shape)\n",
        "  scale = max_dim / long_dim\n",
        "  new_shape = tf.cast(shape * scale, tf.int32)\n",
        "  img = tf.image.resize(img, new_shape)\n",
        "  img = img[tf.newaxis, :]\n",
        "  return img\n",
        "\n",
        "def style_transfer(content, style, quality):\n",
        "    hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
        "    content = convert_img(content, quality)\n",
        "    style = convert_img(style, quality)\n",
        "    stylized_image = hub_model(tf.constant(content), tf.constant(style))[0]\n",
        "    return tensor_to_image(stylized_image)"
      ],
      "metadata": {
        "id": "DWuieHsEieQK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####VQGAN + Clip:"
      ],
      "metadata": {
        "id": "TfgsKLX4hviQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt, generation_quality, detail):\n",
        "    torch.cuda.empty_cache()\n",
        "    clipit.reset_settings()\n",
        "    clipit.add_settings(prompts=prompt,\n",
        "                        aspect='square',\n",
        "                        quality=generation_quality,\n",
        "                        use_pixeldraw=False,\n",
        "                        use_clipdraw=False,\n",
        "                        make_video=False,\n",
        "                        iterations={'draft':30, 'normal': 80, 'better': 150}[detail])\n",
        "    settings = clipit.apply_settings()\n",
        "    clipit.do_init(settings)\n",
        "    clipit.do_run(settings)\n",
        "\n",
        "    return 'output.png'"
      ],
      "metadata": {
        "id": "rPupFTIeV1Ia"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Super Resolution:"
      ],
      "metadata": {
        "id": "Ke481mvwpFAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance(path):\n",
        "  Image.fromarray(path.astype('uint8'), 'RGB').save('temp.jpg', 'jpeg')\n",
        "  r = requests.post(\n",
        "    \"https://api.deepai.org/api/waifu2x\",\n",
        "    files={\n",
        "        'image': open('temp.jpg', 'rb')\n",
        "    },\n",
        "    headers={'api-key': 'quickstart-QUdJIGlzIGNvbWluZy4uLi4K'}\n",
        "  )\n",
        "  urllib.request.urlretrieve(r.json()[\"output_url\"],\"highres.png\")\n",
        "  img = Image.open(\"highres.png\")\n",
        "  return img\n",
        "  "
      ],
      "metadata": {
        "id": "yHdiER4tpIh3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradio Interface:\n",
        "\n"
      ],
      "metadata": {
        "id": "1ThIt0T70Gn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "DrajuBEwhe4P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "kXjaYWvm1dTz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Style Transfer:"
      ],
      "metadata": {
        "id": "FCOVE0lQ1Dn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "content = gr.inputs.Image(shape=None, image_mode=\"RGB\", invert_colors=False, source=\"upload\", tool=\"editor\", type=\"numpy\", label=\"content\")\n",
        "style = gr.inputs.Image(shape=None, image_mode=\"RGB\", invert_colors=False, source=\"upload\", tool=\"editor\", type=\"numpy\", label=\"Style\")\n",
        "quality = gr.inputs.Radio(choices=[1, 2, 3, 4], label=\"Quality\")\n",
        "\n",
        "editor = gr.Interface(style_transfer, \n",
        "                      inputs=[content, style, quality], \n",
        "                      title = \"Style Transfer\",\n",
        "                      article = \"Style transfer is a computer vision technique\"\n",
        "                      +\"that allows us to recompose the content of an image in the style of another\",\n",
        "                      outputs=[\"image\"],\n",
        "                      allow_flagging = \"never\",\n",
        "                      live=False)"
      ],
      "metadata": {
        "id": "FuQWU5aI1Jie"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VQGAN + CLIP:"
      ],
      "metadata": {
        "id": "JaTjpSNR0xRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "prompt = gr.inputs.Textbox(default=\"Flying Cars\", label=\"Text Prompt\")\n",
        "generation_quality = gr.inputs.Radio(choices=['draft', 'normal', 'better'], label=\"Resolution\")\n",
        "detail = gr.inputs.Radio(choices=['draft', 'normal', 'better'], label=\"Detail\")\n",
        "\n",
        "\n",
        "generator = gr.Interface(generate, \n",
        "                         inputs=[prompt, generation_quality, detail], \n",
        "                         outputs=['image'], \n",
        "                         title = \"Text to Art\",\n",
        "                         enable_queue=True, \n",
        "                         live=False)"
      ],
      "metadata": {
        "id": "nckgMOwy07tn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Super Resolution:"
      ],
      "metadata": {
        "id": "zwxq244prnMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original = gr.Image(shape=None, image_mode=\"RGB\", invert_colors=False, source=\"upload\", tool=\"editor\", type=\"numpy\", label=\"content\")\n",
        "enhancer = gr.Interface(enhance, \n",
        "                      inputs=[original], \n",
        "                      title = \"Super Resolution\",\n",
        "                      article = \"2x your image resolution\",\n",
        "                      outputs=[\"image\"],\n",
        "                      allow_flagging = \"never\",\n",
        "                      live=False)"
      ],
      "metadata": {
        "id": "AA7zvOfsrqDC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combined Interface"
      ],
      "metadata": {
        "id": "6fmSQpq__PLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined = gr.TabbedInterface([generator, editor, enhancer], [\"Generate Art\", \"Style Transfer\", \"Super Resolution\"])\n",
        "combined.launch(debug=True, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "N1zAVrua_UOo",
        "outputId": "d3965026-756f-4c46-8fb8-d8b00781e34c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://46799.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://46799.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f94e8ba7750>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://46799.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean Cache:"
      ],
      "metadata": {
        "id": "ggMZTMf7Ky5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "6dRNmoctK1zX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}